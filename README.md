# Multimodal-Learning
List of papers 

Multimodal Representation Learning
==================================
[ICCV-2017] Look, Listen and Learn https://openaccess.thecvf.com/content_iccv_2017/html <br/>/Arandjelovic_Look_Listen_and_ICCV_2017_paper.html <br/>
[NeurIPS-2018] Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization https://proceedings.neurips.cc/paper/2018/hash/c4616f5a24a66668f11ca4fa80525dc4-Abstract.html <br/>
[NeurIPS-2020] Learning Representations from Audio-Visual Spatial Alignment https://proceedings.neurips.cc/paper/2020/hash/328e5d4c166bb340b314d457a208dc83-Abstract.html <br/>
[NeurIPS-2020] Self-Supervised Learning by Cross-Modal Audio-Video Clustering https://proceedings.neurips.cc/paper/2020/hash/6f2268bd1d3d3ebaabb04d6b5d099425-Abstract.html <br/>
[NeurIPS-2020] Labelling Unlabelled Videos From Scratch With Multi-Modal Self-Supervision https://proceedings.neurips.cc/paper/2020/hash/31fefc0e570cb3860f2a6d4b38c6490d-Abstract.html <br/>
[CVPR-2021] Audio-Visual Instance Discrimination with Cross-Modal Agreement https://openaccess.thecvf.com/content/CVPR2021/html <br/>/Morgado_Audio-Visual_Instance_Discrimination_with_Cross-Modal_Agreement_CVPR_2021_paper.html <br/>
[CVPR-2021] Robust Audio-Visual Instance Discrimination https://openaccess.thecvf.com/content/CVPR2021/html <br/>/Morgado_Robust_Audio-Visual_Instance_Discrimination_CVPR_2021_paper.html <br/>
[2021] Unsupervised Sound Localization via Iterative Contrastive Learning https://arxiv.org/abs/2104.00315
[ICCV-2021] Multimodal Clustering Networks for Self-Supervised Learning From Unlabeled Videos https://openaccess.thecvf.com/content/ICCV2021/html <br/>/Chen_Multimodal_Clustering_Networks_for_Self-Supervised_Learning_From_Unlabeled_Videos_ICCV_2021_paper.html <br/>
[2021] OPT: Omni-Perception Pre-Trainer for Cross-Modal Understanding and Generation https://arxiv.org/abs/2107.00249
[NeurIPS-2021] VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text https://proceedings.neurips.cc/paper/2021/hash/cb3213ada48302953cb0f166464ab356-Abstract.html <br/>
[2021] Audio-visual Representation Learning for Anomaly Events Detection in Crowds https://arxiv.org/abs/2110.14862
[ICASSP-2022] Audioclip: Extending Clip to Image, Text and Audio https://ieeexplore.ieee.org/abstract/document/9747631/
[CVPR-2022] MERLOT Reserve: Neural Script Knowledge Through Vision and Language and Sound https://openaccess.thecvf.com/content/CVPR2022/html <br/>/Zellers_MERLOT_Reserve_Neural_Script_Knowledge_Through_Vision_and_Language_and_CVPR_2022_paper.html <br/>
[2022] Probing Visual-Audio Representation for Video Highlight Detection via Hard-Pairs Guided Contrastive Learning https://arxiv.org/abs/2206.10157
[NeurIPS-2022] Non-Linguistic Supervision for Contrastive Learning of Sentence Embeddings https://arxiv.org/abs/2209.09433
[IEEE TMM-2022] Multimodal Information Bottleneck: Learning Minimal Sufficient Unimodal and Multimodal Representations https://arxiv.org/abs/2210.17444
[CVPR-2022] Audiovisual Generalised Zero-shot Learning with Cross-modal Attention and Language https://ieeexplore.ieee.org/document/9880403
[CVPRW-2022] Multi-task Learning for Human Affect Prediction with Auditoryâ€“Visual Synchronized Representation https://ieeexplore.ieee.org/document/9856974
[CVPR-2023] Vision Transformers are Parameter-Efficient Audio-Visual Learners https://arxiv.org/abs/2212.07983
[CVPR-2022] Audio-visual Generalised Zero-shot Learning with Cross-modal Attention and Language https://arxiv.org/abs/2203.03598
[ECCV-2022] Temporal and cross-modal attention for audio-visual zero-shot learning https://arxiv.org/abs/2207.09966
[NeurIPS-2022] u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer to Unlabeled Modality https://arxiv.org/abs/2207.07036
[NeurIPS-2022] Scaling Multimodal Pre-Training via Cross-Modality Gradient Harmonization https://arxiv.org/abs/2211.02077
[AAAI-2023] Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity https://arxiv.org/abs/2111.05329
[ICLR-2023] Contrastive Audio-Visual Masked Autoencoder https://arxiv.org/abs/2210.07839
[ICLR-2023] Jointly Learning Visual and Auditory Speech Representations from Raw Data https://arxiv.org/abs/2212.06246
[WACV-2023] Audio Representation Learning by Distilling Video as Privileged Information https://ieeexplore.ieee.org/document/10041728
[2023] AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations https://arxiv.org/abs/2302.06419
[AAAI-2023] Audio-Visual Contrastive Learning with Temporal Self-Supervision https://arxiv.org/abs/2302.07702
[CVPR-2023] ImageBind One Embedding Space to Bind Them All https://ieeexplore.ieee.org/document/10203733
[NeurIPS-2023] Cross-modal Prompts: Adapting Large Pre-trained Models for Audio-Visual Downstream Tasks https://arxiv.org/abs/2311.05152
[WACV-2024] OmniVec: Learning robust representations with cross modal sharing https://arxiv.org/abs/2311.05709
[InterSpeech-2024] Zero-Shot Fake Video Detection by Audio-Visual Consistency https://arxiv.org/abs/2406.07854


